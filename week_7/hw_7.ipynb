{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Cognitive Neuroscience - Homework 7\n",
    "**Start date: 8th March 2021**\n",
    "\n",
    "**Due date: 15th March 2021**\n",
    "\n",
    "This homework set focuses and expands upon the two articles distributed on moodle, one on [neuroeconomics](https://moodle.helsinki.fi/pluginfile.php/3496193/mod_resource/content/1/447.full%281%29.pdf) and another one on [Bayesian decision theory](https://moodle.helsinki.fi/pluginfile.php/3496194/mod_resource/content/1/1-s2.0-S1364661306001276-main.pdf). Due to the nature of the week's material, exercises are mostly written rather than coding problems.\n",
    "\n",
    "## Submission instructions\n",
    "Submission is by email to hermanni.halva@helsinki.fi. Follow these instructions to submit:  \n",
    "1. Title of the email: \"ccn homework 7 - student_number\"\n",
    "2. When you have completed the exercises, save the notebook. Attach it to the email.\n",
    "3. Also download a pdf of the notebook and attach it.\n",
    "\n",
    "## IMPORTANT\n",
    "1. Don't share your code and answers with others.\n",
    "2. It's your responsibility to ensure that the notebook has fully finished running all the cells, all the plots view properly etc. before submitting it. I will not re-run any code.\n",
    "3. Submit your work by the deadline.\n",
    "4. If you are confused, think there is a mistake or find things too difficult, just ask on github\n",
    "5. If you need help with code, email it to me and I'll have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - utility functions [20 pts]\n",
    "Utility functions aim to quantify the reward a person receives from performing certain actions. Consider two actions, $1$ and $2$, and the amount of times each of them is performed, respectively, $q_1$ and $q_2$. A typical utility function has the shape: $$U=q_1^a q_2^{1-a}$$\n",
    "\n",
    "Questions:\n",
    "1. Consider that we know the person received utility $U=4$ and that the parameter $a=0.5$. Create a plot that shows all the possible combinations of $q_1$ and $q_2$ that could have produced this level of utility. The plot should have $q_1$ as the x-axis and $q_2$ as the y-axis and the plausible combination of values should produce a curve on this plot known as the $\\textit{indifference curve}$. For simplicity, let's assume that $\\min(q_i)=1$.\n",
    "2. Derive analytical expressions (show your derivation) for the marginal utility the person gets from performing one more action $1$, whilst holding other variables constant. Based on this, or otherwise, explain how you would interpret constant $a$?\n",
    "3. Marginal Rate of Substitution (MRS) is defined as the slope of the indifference curve. It describes the amount of times you need to perform action 1 if you were to perform one less of action 2, or vice versa, in order to keep your utility constant. Derive expression for the MRS with above parameters and explain how you would interpret its general shape.\n",
    "4. In contrast to above, what would be the interpretations of the MRS' for the following utility functions:\n",
    "$$\\begin{align}\n",
    "&\\text{a.  } U=a q_1 + b q_2 \\,\\,\\text{ where the constants are > 0} \\\\\n",
    "&\\text{b.  } U=min\\{q_1, q_2\\}\n",
    "\\end{align}$$\n",
    "5. Consider that there is a constraint on the total amount of energy a person can use on the two actions. Define this budget as:\n",
    "$$E=c_1q_1 + c_2q_2$$\n",
    "where $c_1$ and $c_2$ essentially describe the amount of energy it 'costs' to perform each of the two actions. Subject to this constraint, and assuming that now the person's utility function is\n",
    "$$U=(q_1^p+q_2^p)^{1/p},$$\n",
    "where $p<1$ and $p \\ne 0$. Find the optimal, utility maximizing, $q_1$ and $q_2$, in terms of $E$, $c_1$ and $c_2$.\n",
    "6. Plot the solution you found above, similar to what you did in the first question, but dont forget about including the energy constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Bayesian inference [25 pts]\n",
    "\n",
    "Note: If you need to brush up on your basic Bayesian/probability statistics, the first chapers [here](https://users.aalto.fi/~ave/BDA3.pdf) may be useful.\n",
    "\n",
    "Questions:\n",
    "1. Assuming that human brains are in some sense Bayesian, we can assume that our reactions/predictions are also in some way computed in Bayesian manner. In other words, our predictions would follow the predictive probability distribution of the form:\n",
    "$$p(\\tilde{y}|Y=y)=\\int p(\\tilde{y}|\\theta)p(\\theta|y)d\\theta$$ where $\\tilde{y}$ is unknown future state and $y$ is the current observed state of the world, and  $\\theta$ some parameters. **Your task** is to prove above equality staring from the left-hand side. State all the assumptions you use, to justify each step of your proof.\n",
    "\n",
    "\n",
    "\n",
    "2. Sequential Bayesian learning. Suppose again that we have a Bayesian model of the world where we measure the likelihood of the current state of the world as $p(y_1|\\theta)$. We have some prior on the parameters i.e. $p(\\theta)$. From this we obtain the posterior likelihood $p(\\theta|y_1)$. Now assume we next observe some new state $y_2$. We of course want to use this new data to improve our inference i.e. to calculate $p(\\theta|y_1, y_2)$. **Show that**\n",
    "$$p(\\theta|y_1, y_2) \\propto p(y_2|\\theta)p(\\theta|y_1)$$\n",
    "i.e. that the old posterior kind of acts like a new prior!\n",
    "\n",
    "\n",
    "3. Scientist found a neuron that usually fires in response to some stimulus M. Specifically, $\\theta$ gives the proportion of times when the neuron fired in response to receiving M. The neuron however seems to fire sometimes in response to some other stimuli too: $\\lambda$ is the probability that the cell fires when stimulus is something else than M. Assume that $100q\\%$ of all stimuli are type M. Answer the following:\n",
    "\n",
    "    a.) The neuron does not fire in response to a stimulus. What is the probability that it was stimulus M?\n",
    "    \n",
    "    b.) In order to be more certain, a.) is repeated with exactly the same stimulus.   Assuming that repeat tests are conditionally independent given the true status of the stimulus, show that the probability that the neuron will *not* fire is \n",
    "    $$ \\frac{A(1-\\lambda)^2+(1-\\theta)^2}{(1-\\theta)+A(1-\\lambda)}$$\n",
    "    what is the value of $A$?\n",
    "    \n",
    "\n",
    "\n",
    "4. Bayesian decision theory aims to maximize utility / minimize loss under uncertainty. Consider that you are playing tennis and your opponent serves the ball. Your visual observation of the projectile of the ball is contained in the variable $y$. You calculate the posterior of the location of where you expect the ball to land $p(\\theta|y)$ based on the visual information. You also need to choose action $a$ e.g. where to move on the court. For simplicity, let's assume the following loss function \n",
    "$$L(\\theta, a)=L(\\theta, a)=\\begin{cases} 0 \\text{ if } |\\theta-a| \\le \\epsilon \\\\ 1 \\text{ if } |\\theta-a| > \\epsilon \\end{cases}$$ for some very small $\\epsilon$. Using function $a = d(y)$, you take some action based on the visual information (e.g. where to move). The expected loss is then\n",
    "$$E_{\\theta|y}\\left[L(\\theta, a)\\right]=\\int_{-\\infty}^{\\infty} L(\\theta, a)p(\\theta|y)d\\theta$$\n",
    "show that the optimal action $a$ is the posterior mode of $p(\\theta|y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Utility paradoxes [10 pts]\n",
    "\n",
    "1. Consider two possible lotteries (1.) you get €1000 with certainty (2.) with 95% you get €1500 but with 5% get €0. A person, for some reason, prefers lottery (1.). Define a *strictly increasing* utility function that represents this persons preferences over the above lotteries. Show this with some simple code below.\n",
    "\n",
    "2. Consider the following experiments\n",
    "        Experiment 1\n",
    "            - lottery A: +€1K (100% probability)\n",
    "            - lottery B: +€1K (89%), +€5K (10%), €0 (1%)\n",
    "            \n",
    "        Experiment 2\n",
    "            - lottery A: €0 (89%), +€1K (11%)\n",
    "            - lottery B: €0 (90%), +€5K (10%) \n",
    "\n",
    "    Real empirical results show that a typical person prefers lottery 1A to 1B, but 2B to 2A. Show that this is paradoxical i.e. show formally that a mathematical contradiction occurs if above holds. Assume some generic utility function $U(W)$ where $W$ denotes money, but notice you don't need to specify the form of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
